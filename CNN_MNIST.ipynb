{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN MNIST",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TQ9iRTOblAR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niFjP1ZuJCc5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0f1847a2-9d97-48ea-9ec2-3dbbf30f9036"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u69SsN1AJE2S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Dense, Activation, Flatten, Input  ##flatten for maxpool\n",
        "from keras.layers import Conv2D, MaxPool2D\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ej4_UaM_KXdB",
        "colab_type": "text"
      },
      "source": [
        "## load input data(x)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCngrwEkJKpj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8970b8c5-8576-4200-a175-985bc91b44eb"
      },
      "source": [
        "(x_train,y_train), (x_test,y_test) = mnist.load_data()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqvVaY3tJP9W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for CNN, reshape data to (28,28,1) ;rgb1->3\n",
        "x_train = x_train.reshape(len(x_train), 28,28,1)  \n",
        "x_test = x_test.reshape(len(x_test), 28,28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZW4l-zKKGuY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "44054cf5-3ab9-4c79-cd32-391a6d61db0c"
      },
      "source": [
        "plt.imshow(x_train[100].reshape(28,28), cmap = 'Greys')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fd56fd9e4e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhB9IivADSRF+ICnCDyRF+IGkCD+Q1P8DLYf4GPdPRpMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1MDGNckLjEo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#nomralize\n",
        "x_train = (x_train - x_train.min()) / (x_train.max() - x_train.min())\n",
        "x_test = (x_test - x_test.min()) / (x_test.max() - x_test.min())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abqBNYcxLHuw",
        "colab_type": "text"
      },
      "source": [
        "## y - one-hot encoding (utils.to_catagorial )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvDdX-biLHYZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = np_utils.to_categorical(y_train, 10)\n",
        "y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-P5vBjqLt4C",
        "colab_type": "text"
      },
      "source": [
        "## construct CNN (function API)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iNHUCwFKUAJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f1 = Conv2D(4,#filiters' num\n",
        "           (5,5), #filiter's size\n",
        "           padding = 'same', ## padding-> 加多少0使輸出形狀一樣\n",
        "           input_shape = (28,28,1),\n",
        "           activation = 'relu')\n",
        "f1_1 = MaxPool2D(pool_size=(2,2))\n",
        "\n",
        "f2 = Conv2D(8,#filiters' num\n",
        "           (5,5), #filiter's size\n",
        "           padding = 'same', ## padding-> 加多少0使輸出形狀一樣\n",
        "           activation = 'relu')\n",
        "f2_1 = MaxPool2D(pool_size=(2,2))\n",
        "\n",
        "f3 = Conv2D(16,#filiters' num\n",
        "           (5,5), #filiter's size\n",
        "           padding = 'same', ## padding-> 加多少0使輸出形狀一樣\n",
        "           activation = 'relu')\n",
        "f3_1 = MaxPool2D(pool_size=(2,2))\n",
        "\n",
        "f4 = Conv2D(32,#filiters' num\n",
        "           (5,5), #filiter's size\n",
        "           padding = 'same', ## padding-> 加多少0使輸出形狀一樣\n",
        "           activation = 'relu')\n",
        "f4_1 = MaxPool2D(pool_size=(2,2))\n",
        "\n",
        "f5 = Flatten()\n",
        "\n",
        "f6 = Dense(50, activation='relu')\n",
        "\n",
        "f7 = Dense(10, activation='softmax')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnTiEHl1Rzvb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5aeb8ecd-a89f-4e8d-ad64-fa9d92c4c6ee"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeqOim7uTUC5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fd523b71-e38d-425b-f51f-28d3d0a33fdc"
      },
      "source": [
        "x = Input(shape = (28, 28, 1))\n",
        "x"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'input_1:0' shape=(?, 28, 28, 1) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YM5Q_fzR48b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "e69b0656-8ac5-4c92-9d31-1d14236ab636"
      },
      "source": [
        "hid1 = f1(x)\n",
        "hid1_1 = f1_1(hid1)\n",
        "\n",
        "hid2 = f2(hid1_1)\n",
        "hid2_1 = f2_1(hid2)\n",
        "\n",
        "hid3 = f3(hid2_1)\n",
        "hid3_1 = f3_1(hid3)\n",
        "\n",
        "hid4 = f4(hid3_1)\n",
        "hid4_1 = f4_1(hid4)\n",
        "\n",
        "hid5 = f5(hid4_1)\n",
        "\n",
        "hid6 = f6(hid5)\n",
        "\n",
        "y = f7(hid6)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzlhlt5mTIEM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "16762e26-d883-4312-ed2c-8caa36ddfc24"
      },
      "source": [
        "model = Model(x,y) #產生model包輸入輸出\n",
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 28, 28, 4)         104       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 4)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 14, 14, 8)         808       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 8)           0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 7, 7, 16)          3216      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 3, 3, 32)          12832     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 50)                1650      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                510       \n",
            "=================================================================\n",
            "Total params: 19,120\n",
            "Trainable params: 19,120\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yj2gh_jNTt9c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss = 'categorical_crossentropy', optimizer=Adam(lr=0.001, \n",
        "                                                                beta_1=0.9, \n",
        "                                                                beta_2=0.999, \n",
        "                                                                epsilon=None, \n",
        "                                                                decay=0.0, \n",
        "                                                                amsgrad=False),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sz8scSNyT7a6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2417
        },
        "outputId": "f4ce854f-27fd-4f85-8610-449a0c607002"
      },
      "source": [
        "model1 = model.fit(x_train,y_train, batch_size = 100, epochs = 100,\n",
        "         verbose = 1,\n",
        "         validation_data = (x_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "60000/60000 [==============================] - 54s 900us/step - loss: 0.4167 - acc: 0.8719 - val_loss: 0.1394 - val_acc: 0.9561\n",
            "Epoch 2/100\n",
            "60000/60000 [==============================] - 54s 892us/step - loss: 0.1272 - acc: 0.9613 - val_loss: 0.0919 - val_acc: 0.9701\n",
            "Epoch 3/100\n",
            "60000/60000 [==============================] - 54s 893us/step - loss: 0.0959 - acc: 0.9699 - val_loss: 0.0728 - val_acc: 0.9762\n",
            "Epoch 4/100\n",
            "60000/60000 [==============================] - 54s 895us/step - loss: 0.0778 - acc: 0.9750 - val_loss: 0.0596 - val_acc: 0.9813\n",
            "Epoch 5/100\n",
            "60000/60000 [==============================] - 53s 889us/step - loss: 0.0673 - acc: 0.9784 - val_loss: 0.0654 - val_acc: 0.9789\n",
            "Epoch 6/100\n",
            "60000/60000 [==============================] - 54s 899us/step - loss: 0.0582 - acc: 0.9818 - val_loss: 0.0720 - val_acc: 0.9771\n",
            "Epoch 7/100\n",
            "60000/60000 [==============================] - 54s 894us/step - loss: 0.0525 - acc: 0.9829 - val_loss: 0.0518 - val_acc: 0.9828\n",
            "Epoch 8/100\n",
            "60000/60000 [==============================] - 54s 893us/step - loss: 0.0470 - acc: 0.9851 - val_loss: 0.0494 - val_acc: 0.9831\n",
            "Epoch 9/100\n",
            "60000/60000 [==============================] - 53s 891us/step - loss: 0.0427 - acc: 0.9858 - val_loss: 0.0557 - val_acc: 0.9816\n",
            "Epoch 10/100\n",
            "60000/60000 [==============================] - 54s 895us/step - loss: 0.0388 - acc: 0.9876 - val_loss: 0.0487 - val_acc: 0.9851\n",
            "Epoch 11/100\n",
            "60000/60000 [==============================] - 54s 894us/step - loss: 0.0381 - acc: 0.9877 - val_loss: 0.0474 - val_acc: 0.9848\n",
            "Epoch 12/100\n",
            "60000/60000 [==============================] - 54s 896us/step - loss: 0.0330 - acc: 0.9892 - val_loss: 0.0407 - val_acc: 0.9873\n",
            "Epoch 13/100\n",
            "60000/60000 [==============================] - 53s 891us/step - loss: 0.0297 - acc: 0.9905 - val_loss: 0.0427 - val_acc: 0.9867\n",
            "Epoch 14/100\n",
            "60000/60000 [==============================] - 53s 891us/step - loss: 0.0265 - acc: 0.9917 - val_loss: 0.0492 - val_acc: 0.9856\n",
            "Epoch 15/100\n",
            "60000/60000 [==============================] - 54s 892us/step - loss: 0.0252 - acc: 0.9913 - val_loss: 0.0534 - val_acc: 0.9850\n",
            "Epoch 16/100\n",
            "60000/60000 [==============================] - 54s 895us/step - loss: 0.0221 - acc: 0.9928 - val_loss: 0.0540 - val_acc: 0.9832\n",
            "Epoch 17/100\n",
            "60000/60000 [==============================] - 53s 890us/step - loss: 0.0216 - acc: 0.9928 - val_loss: 0.0442 - val_acc: 0.9880\n",
            "Epoch 18/100\n",
            "60000/60000 [==============================] - 54s 896us/step - loss: 0.0209 - acc: 0.9929 - val_loss: 0.0475 - val_acc: 0.9873\n",
            "Epoch 19/100\n",
            "60000/60000 [==============================] - 53s 891us/step - loss: 0.0179 - acc: 0.9941 - val_loss: 0.0377 - val_acc: 0.9883\n",
            "Epoch 20/100\n",
            "60000/60000 [==============================] - 53s 890us/step - loss: 0.0171 - acc: 0.9942 - val_loss: 0.0479 - val_acc: 0.9861\n",
            "Epoch 21/100\n",
            "60000/60000 [==============================] - 54s 892us/step - loss: 0.0174 - acc: 0.9940 - val_loss: 0.0417 - val_acc: 0.9879\n",
            "Epoch 22/100\n",
            "60000/60000 [==============================] - 54s 893us/step - loss: 0.0162 - acc: 0.9948 - val_loss: 0.0448 - val_acc: 0.9894\n",
            "Epoch 23/100\n",
            "60000/60000 [==============================] - 54s 892us/step - loss: 0.0137 - acc: 0.9954 - val_loss: 0.0619 - val_acc: 0.9868\n",
            "Epoch 24/100\n",
            "60000/60000 [==============================] - 54s 895us/step - loss: 0.0131 - acc: 0.9957 - val_loss: 0.0611 - val_acc: 0.9865\n",
            "Epoch 25/100\n",
            "60000/60000 [==============================] - 53s 890us/step - loss: 0.0137 - acc: 0.9955 - val_loss: 0.0500 - val_acc: 0.9876\n",
            "Epoch 26/100\n",
            "60000/60000 [==============================] - 53s 890us/step - loss: 0.0136 - acc: 0.9952 - val_loss: 0.0590 - val_acc: 0.9872\n",
            "Epoch 27/100\n",
            "60000/60000 [==============================] - 54s 893us/step - loss: 0.0137 - acc: 0.9957 - val_loss: 0.0503 - val_acc: 0.9880\n",
            "Epoch 28/100\n",
            "60000/60000 [==============================] - 53s 888us/step - loss: 0.0110 - acc: 0.9964 - val_loss: 0.0720 - val_acc: 0.9843\n",
            "Epoch 29/100\n",
            "60000/60000 [==============================] - 54s 895us/step - loss: 0.0112 - acc: 0.9960 - val_loss: 0.0550 - val_acc: 0.9872\n",
            "Epoch 30/100\n",
            "60000/60000 [==============================] - 53s 891us/step - loss: 0.0113 - acc: 0.9961 - val_loss: 0.0590 - val_acc: 0.9862\n",
            "Epoch 31/100\n",
            "60000/60000 [==============================] - 53s 890us/step - loss: 0.0133 - acc: 0.9956 - val_loss: 0.0471 - val_acc: 0.9877\n",
            "Epoch 32/100\n",
            "60000/60000 [==============================] - 54s 892us/step - loss: 0.0104 - acc: 0.9962 - val_loss: 0.0649 - val_acc: 0.9871\n",
            "Epoch 33/100\n",
            "60000/60000 [==============================] - 54s 894us/step - loss: 0.0101 - acc: 0.9965 - val_loss: 0.0624 - val_acc: 0.9866\n",
            "Epoch 34/100\n",
            "60000/60000 [==============================] - 54s 897us/step - loss: 0.0077 - acc: 0.9975 - val_loss: 0.0605 - val_acc: 0.9847\n",
            "Epoch 35/100\n",
            "60000/60000 [==============================] - 54s 898us/step - loss: 0.0093 - acc: 0.9966 - val_loss: 0.0551 - val_acc: 0.9875\n",
            "Epoch 36/100\n",
            "60000/60000 [==============================] - 54s 892us/step - loss: 0.0106 - acc: 0.9964 - val_loss: 0.0919 - val_acc: 0.9810\n",
            "Epoch 37/100\n",
            "60000/60000 [==============================] - 53s 891us/step - loss: 0.0088 - acc: 0.9971 - val_loss: 0.0812 - val_acc: 0.9832\n",
            "Epoch 38/100\n",
            "60000/60000 [==============================] - 54s 892us/step - loss: 0.0113 - acc: 0.9964 - val_loss: 0.0572 - val_acc: 0.9875\n",
            "Epoch 39/100\n",
            "60000/60000 [==============================] - 53s 880us/step - loss: 0.0085 - acc: 0.9973 - val_loss: 0.0662 - val_acc: 0.9860\n",
            "Epoch 40/100\n",
            "60000/60000 [==============================] - 54s 892us/step - loss: 0.0097 - acc: 0.9969 - val_loss: 0.0566 - val_acc: 0.9890\n",
            "Epoch 41/100\n",
            "60000/60000 [==============================] - 54s 899us/step - loss: 0.0091 - acc: 0.9968 - val_loss: 0.0577 - val_acc: 0.9888\n",
            "Epoch 42/100\n",
            "60000/60000 [==============================] - 54s 892us/step - loss: 0.0070 - acc: 0.9976 - val_loss: 0.0771 - val_acc: 0.9856\n",
            "Epoch 43/100\n",
            "60000/60000 [==============================] - 54s 892us/step - loss: 0.0064 - acc: 0.9978 - val_loss: 0.0610 - val_acc: 0.9888\n",
            "Epoch 44/100\n",
            "60000/60000 [==============================] - 54s 892us/step - loss: 0.0074 - acc: 0.9976 - val_loss: 0.0780 - val_acc: 0.9872\n",
            "Epoch 45/100\n",
            "60000/60000 [==============================] - 53s 890us/step - loss: 0.0099 - acc: 0.9969 - val_loss: 0.0717 - val_acc: 0.9870\n",
            "Epoch 46/100\n",
            "60000/60000 [==============================] - 53s 891us/step - loss: 0.0075 - acc: 0.9976 - val_loss: 0.0806 - val_acc: 0.9869\n",
            "Epoch 47/100\n",
            "60000/60000 [==============================] - 54s 897us/step - loss: 0.0100 - acc: 0.9968 - val_loss: 0.0732 - val_acc: 0.9865\n",
            "Epoch 48/100\n",
            "60000/60000 [==============================] - 53s 892us/step - loss: 0.0039 - acc: 0.9988 - val_loss: 0.0682 - val_acc: 0.9888\n",
            "Epoch 49/100\n",
            "60000/60000 [==============================] - 53s 892us/step - loss: 0.0100 - acc: 0.9969 - val_loss: 0.0615 - val_acc: 0.9871\n",
            "Epoch 50/100\n",
            "60000/60000 [==============================] - 54s 893us/step - loss: 0.0078 - acc: 0.9973 - val_loss: 0.0627 - val_acc: 0.9892\n",
            "Epoch 51/100\n",
            "60000/60000 [==============================] - 54s 892us/step - loss: 0.0053 - acc: 0.9982 - val_loss: 0.0792 - val_acc: 0.9866\n",
            "Epoch 52/100\n",
            "60000/60000 [==============================] - 54s 892us/step - loss: 0.0079 - acc: 0.9974 - val_loss: 0.0727 - val_acc: 0.9878\n",
            "Epoch 53/100\n",
            "60000/60000 [==============================] - 54s 903us/step - loss: 0.0048 - acc: 0.9985 - val_loss: 0.0674 - val_acc: 0.9874\n",
            "Epoch 54/100\n",
            "60000/60000 [==============================] - 54s 897us/step - loss: 0.0086 - acc: 0.9972 - val_loss: 0.0602 - val_acc: 0.9887\n",
            "Epoch 55/100\n",
            "60000/60000 [==============================] - 54s 893us/step - loss: 0.0073 - acc: 0.9977 - val_loss: 0.0792 - val_acc: 0.9865\n",
            "Epoch 56/100\n",
            "60000/60000 [==============================] - 54s 893us/step - loss: 0.0080 - acc: 0.9974 - val_loss: 0.0763 - val_acc: 0.9857\n",
            "Epoch 57/100\n",
            "60000/60000 [==============================] - 54s 900us/step - loss: 0.0080 - acc: 0.9974 - val_loss: 0.0772 - val_acc: 0.9874\n",
            "Epoch 58/100\n",
            "60000/60000 [==============================] - 54s 902us/step - loss: 0.0058 - acc: 0.9981 - val_loss: 0.0839 - val_acc: 0.9868\n",
            "Epoch 59/100\n",
            "60000/60000 [==============================] - 54s 895us/step - loss: 0.0051 - acc: 0.9984 - val_loss: 0.0712 - val_acc: 0.9889\n",
            "Epoch 60/100\n",
            "60000/60000 [==============================] - 54s 897us/step - loss: 0.0068 - acc: 0.9979 - val_loss: 0.0678 - val_acc: 0.9887\n",
            "Epoch 61/100\n",
            "60000/60000 [==============================] - 54s 901us/step - loss: 0.0058 - acc: 0.9983 - val_loss: 0.0699 - val_acc: 0.9872\n",
            "Epoch 62/100\n",
            "60000/60000 [==============================] - 54s 896us/step - loss: 0.0061 - acc: 0.9981 - val_loss: 0.0771 - val_acc: 0.9876\n",
            "Epoch 63/100\n",
            "60000/60000 [==============================] - 54s 894us/step - loss: 0.0058 - acc: 0.9983 - val_loss: 0.0800 - val_acc: 0.9879\n",
            "Epoch 64/100\n",
            "60000/60000 [==============================] - 54s 897us/step - loss: 0.0047 - acc: 0.9985 - val_loss: 0.0799 - val_acc: 0.9875\n",
            "Epoch 65/100\n",
            "60000/60000 [==============================] - 53s 891us/step - loss: 0.0077 - acc: 0.9976 - val_loss: 0.0802 - val_acc: 0.9860\n",
            "Epoch 66/100\n",
            "60000/60000 [==============================] - 53s 891us/step - loss: 0.0070 - acc: 0.9977 - val_loss: 0.0929 - val_acc: 0.9845\n",
            "Epoch 67/100\n",
            "60000/60000 [==============================] - 54s 897us/step - loss: 0.0048 - acc: 0.9985 - val_loss: 0.0650 - val_acc: 0.9892\n",
            "Epoch 68/100\n",
            "10500/60000 [====>.........................] - ETA: 40s - loss: 9.0826e-04 - acc: 0.9998"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5OmPtkkUFKT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}